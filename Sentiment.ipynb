{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sentiment.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "sSjUfy0aCXyx"
      },
      "source": [
        "\n",
        "import numpy as np \n",
        "import pandas as pd \n",
        "import matplotlib.pyplot as plt \n",
        "from sklearn.svm import SVC\n",
        "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
        "from sklearn.metrics import accuracy_score,confusion_matrix, f1_score #for accuracy and scores\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.model_selection import train_test_split\n",
        "from mlxtend.plotting import plot_confusion_matrix\n",
        "from sklearn.metrics import accuracy_score,confusion_matrix,classification_report\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from keras.layers import Convolution1D, GlobalMaxPooling1D\n",
        "from keras.layers import Dropout\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding,LSTM, Flatten, Dropout\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.initializers import Constant\n",
        "from sklearn.metrics import accuracy_score\n",
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "An6dkeJvDJd6",
        "outputId": "3615a918-8201-4c8e-e44a-c0c13052ef8f"
      },
      "source": [
        "# Loading the dataset into Pandas\n",
        "    \n",
        "\n",
        "path = '/content/drive/MyDrive/Tweets.csv'\n",
        "data_df = pd.read_csv(path)\n",
        "\n",
        "\n",
        "#Pandas: whats the data row count?\n",
        "data_df.shape\n",
        "    \n",
        "#Pandas: whats the distribution of the data?\n",
        "data_df.describe()\n",
        "    \n",
        "#Pandas: What types of data do i have?\n",
        "data_df.info()    "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 14640 entries, 0 to 14639\n",
            "Data columns (total 15 columns):\n",
            " #   Column                        Non-Null Count  Dtype  \n",
            "---  ------                        --------------  -----  \n",
            " 0   tweet_id                      14640 non-null  int64  \n",
            " 1   airline_sentiment             14640 non-null  object \n",
            " 2   airline_sentiment_confidence  14640 non-null  float64\n",
            " 3   negativereason                9178 non-null   object \n",
            " 4   negativereason_confidence     10522 non-null  float64\n",
            " 5   airline                       14640 non-null  object \n",
            " 6   airline_sentiment_gold        40 non-null     object \n",
            " 7   name                          14640 non-null  object \n",
            " 8   negativereason_gold           32 non-null     object \n",
            " 9   retweet_count                 14640 non-null  int64  \n",
            " 10  text                          14640 non-null  object \n",
            " 11  tweet_coord                   1019 non-null   object \n",
            " 12  tweet_created                 14640 non-null  object \n",
            " 13  tweet_location                9907 non-null   object \n",
            " 14  user_timezone                 9820 non-null   object \n",
            "dtypes: float64(2), int64(2), object(11)\n",
            "memory usage: 1.7+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        },
        "id": "Y04I18mYDv9i",
        "outputId": "e7c76368-3c5d-4798-f9c1-14fbe787d29f"
      },
      "source": [
        "data_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet_id</th>\n",
              "      <th>airline_sentiment</th>\n",
              "      <th>airline_sentiment_confidence</th>\n",
              "      <th>negativereason</th>\n",
              "      <th>negativereason_confidence</th>\n",
              "      <th>airline</th>\n",
              "      <th>airline_sentiment_gold</th>\n",
              "      <th>name</th>\n",
              "      <th>negativereason_gold</th>\n",
              "      <th>retweet_count</th>\n",
              "      <th>text</th>\n",
              "      <th>tweet_coord</th>\n",
              "      <th>tweet_created</th>\n",
              "      <th>tweet_location</th>\n",
              "      <th>user_timezone</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>570306133677760513</td>\n",
              "      <td>neutral</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Virgin America</td>\n",
              "      <td>NaN</td>\n",
              "      <td>cairdin</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>@VirginAmerica What @dhepburn said.</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2015-02-24 11:35:52 -0800</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Eastern Time (US &amp; Canada)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>570301130888122368</td>\n",
              "      <td>positive</td>\n",
              "      <td>0.3486</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>Virgin America</td>\n",
              "      <td>NaN</td>\n",
              "      <td>jnardino</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2015-02-24 11:15:59 -0800</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Pacific Time (US &amp; Canada)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>570301083672813571</td>\n",
              "      <td>neutral</td>\n",
              "      <td>0.6837</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Virgin America</td>\n",
              "      <td>NaN</td>\n",
              "      <td>yvonnalynn</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2015-02-24 11:15:48 -0800</td>\n",
              "      <td>Lets Play</td>\n",
              "      <td>Central Time (US &amp; Canada)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>570301031407624196</td>\n",
              "      <td>negative</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>Bad Flight</td>\n",
              "      <td>0.7033</td>\n",
              "      <td>Virgin America</td>\n",
              "      <td>NaN</td>\n",
              "      <td>jnardino</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2015-02-24 11:15:36 -0800</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Pacific Time (US &amp; Canada)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>570300817074462722</td>\n",
              "      <td>negative</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>Can't Tell</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>Virgin America</td>\n",
              "      <td>NaN</td>\n",
              "      <td>jnardino</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2015-02-24 11:14:45 -0800</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Pacific Time (US &amp; Canada)</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             tweet_id  ...               user_timezone\n",
              "0  570306133677760513  ...  Eastern Time (US & Canada)\n",
              "1  570301130888122368  ...  Pacific Time (US & Canada)\n",
              "2  570301083672813571  ...  Central Time (US & Canada)\n",
              "3  570301031407624196  ...  Pacific Time (US & Canada)\n",
              "4  570300817074462722  ...  Pacific Time (US & Canada)\n",
              "\n",
              "[5 rows x 15 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LM54APa4D_XA",
        "outputId": "c711f552-eb18-492e-bdd1-4f3239bc8180"
      },
      "source": [
        "sentiment_counts = data_df.airline_sentiment.value_counts()\n",
        "number_of_tweets = data_df.tweet_id.count()\n",
        "print(sentiment_counts)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "negative    9178\n",
            "neutral     3099\n",
            "positive    2363\n",
            "Name: airline_sentiment, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 421
        },
        "id": "EZaY3vyOELvK",
        "outputId": "398851a0-1a2c-49ce-c7b7-53ff5584e08b"
      },
      "source": [
        "counter = data_df.airline_sentiment.value_counts()\n",
        "index = [1,2,3]\n",
        "plt.figure(1,figsize=(12,6))\n",
        "plt.bar(index,counter,color=['green','red','blue'])\n",
        "plt.xticks(index,['negative','neutral','positive'],rotation=0)\n",
        "plt.xlabel('Sentiment Type')\n",
        "plt.ylabel('Sentiment Count')\n",
        "plt.title('Count of Type of Sentiment')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Count of Type of Sentiment')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gsD4u_AKERJv",
        "outputId": "89829407-96b7-4df6-f534-2d159f15f9ef"
      },
      "source": [
        "# Count tweets\n",
        "print(len(data_df))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "14640\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 507
        },
        "id": "VarNeZ11EbCq",
        "outputId": "1970d11a-6b30-4b17-f9ff-405fb7753d69"
      },
      "source": [
        "neg_tweets = data_df.groupby(['airline','airline_sentiment']).count().iloc[:,0]\n",
        "total_tweets = data_df.groupby(['airline'])['airline_sentiment'].count()\n",
        "\n",
        "my_dict = {'American':neg_tweets[0] / total_tweets[0],'Delta':neg_tweets[3] / total_tweets[1],'Southwest': neg_tweets[6] / total_tweets[2],\n",
        "'US Airways': neg_tweets[9] / total_tweets[3],'United': neg_tweets[12] / total_tweets[4],'Virgin': neg_tweets[15] / total_tweets[5]}\n",
        "perc = pd.DataFrame.from_dict(my_dict, orient = 'index')\n",
        "perc.columns = ['Percent Negative']\n",
        "print(perc)\n",
        "ax = perc.plot(kind = 'bar', rot=0, colormap = 'Greens_r', figsize = (15,6))\n",
        "ax.set_xlabel('Airlines')\n",
        "ax.set_ylabel('Percentage of negative tweets')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "            Percent Negative\n",
            "American            0.710402\n",
            "Delta               0.429793\n",
            "Southwest           0.490083\n",
            "US Airways          0.776862\n",
            "United              0.688906\n",
            "Virgin              0.359127\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA3gAAAFzCAYAAABsNqukAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3de5hdZX3//feHAIKCKBD7tARI0AhyDBCpYLGc8oCKwVo5BG2l2uIBRNHqTxTQoli1VKsUBTwUf1YNCFJTjAIqIBQRAkSQABoBJehTDmI4KJDA9/ljr4HNOJPZM8maJDvv13XNlb3Wvvda32EWe6/Pvu91r1QVkiRJkqTV31oruwBJkiRJ0ophwJMkSZKkPmHAkyRJkqQ+YcCTJEmSpD5hwJMkSZKkPmHAkyRJkqQ+sfbKLmC0Nt1005o8efLKLkOSJEmSVoprr7323qqaONRzq13Amzx5MvPmzVvZZUiSJEnSSpHkl8M91+oQzSQHJLk1ycIk7xvi+S2SXJLk+iQ3JHlFm/VIkiRJUj9rLeAlmQCcBrwc2BaYlWTbQc2OB86pqp2Bw4DPtlWPJEmSJPW7NnvwdgMWVtVtVfUYMBs4aFCbAp7dPN4I+HWL9UiSJElSX2vzGrzNgDu7lhcBfz6ozYeAi5K8HXgWsF+L9UiSJEl9ZcmSJSxatIhHHnlkZZeiFqy33npMmjSJddZZp+fXrOxJVmYBZ1XVvybZHfhKku2r6onuRkmOBI4E2GKLLVZCmZIkSdKqZ9GiRWy44YZMnjyZJCu7HK1AVcV9993HokWLmDJlSs+va3OI5l3A5l3Lk5p13d4EnANQVT8C1gM2HbyhqjqzqqZX1fSJE4ecDVSSJEla4zzyyCNssskmhrs+lIRNNtlk1L2zbQa8a4CpSaYkWZfOJCpzBrX5FbAvQJIX0Ql497RYkyRJktRXDHf9ayx/29YCXlUtBY4GLgRupjNb5k1JTkoys2n2buAfkvwE+DpwRFVVWzVJkiRJWrEmTJjAtGnT2H777Tn44IP5/e9/P+41XHrppVx55ZVDPnfWWWex1lprccMNNzy5bvvtt+eOO+5YoTXMnz+fuXPnPrk8Z84cPvaxj63QffSi1WvwqmouMHfQuhO7Hi8AXtpmDZIkSdKaIjMmrdDt1cWLRmyz/vrrM3/+fABe97rXcfrpp/Oud71rxNctXbqUtddeMXHk0ksvZYMNNmCPPfYY8vlJkyZx8sknc/bZZ6+Q/Q1l/vz5zJs3j1e8onNr75kzZzJz5swRXrXitXqjc0mSJElrjj333JOFCxfy8MMP88Y3vpHddtuNnXfemW9961tApzdt5syZ7LPPPuy777489NBD/N3f/R077LADO+64I+eddx4AF110Ebvvvju77LILBx98MA899BAAkydP5oMf/CC77LILO+ywA7fccgt33HEHp59+Op/61KeYNm0al19++R/VdeCBB3LTTTdx6623/tFzw+1r7ty5bLPNNuy6664cc8wxHHjggQBcffXV7L777uy8887sscce3HrrrTz22GOceOKJnH322UybNo2zzz6bs846i6OPPprFixez5ZZb8sQTnXkkH374YTbffHOWLFnCL37xCw444AB23XVX9txzT2655Zbl/hsY8CRJkiQtt6VLl/Kd73yHHXbYgZNPPpl99tmHq6++mksuuYT3vOc9PPzwwwBcd911nHvuuVx22WV8+MMfZqONNuLGG2/khhtuYJ999uHee+/lIx/5CN/73ve47rrrmD59Op/85Cef3M+mm27Kddddx1vf+lZOOeUUJk+ezFve8haOPfZY5s+fz5577vlHta211lq8973v5aMf/ejT1g+3r0ceeYQ3v/nNfOc73+Haa6/lnnuemiZkm2224fLLL+f666/npJNO4v3vfz/rrrsuJ510Eoceeijz58/n0EMPfbL9RhttxLRp07jssssAuOCCC9h///1ZZ511OPLIIzn11FO59tprOeWUU3jb29623H+HlX2bBEmSJEmrsT/84Q9MmzYN6PTgvelNb2KPPfZgzpw5nHLKKUBnts9f/epXAMyYMYONN94YgO9973vMnj37yW0997nP5YILLmDBggW89KWdK7kee+wxdt999yfbvOY1rwFg11135Zvf/GbPdR5++OGcfPLJ3H777U+uu+qqq4bc1y233MJWW2315O0JZs2axZlnngnA4sWLecMb3sDPf/5zkrBkyZIR933ooYdy9tlns/feezN79mze9ra38dBDD3HllVdy8MEHP9nu0Ucf7fn3GY4BT5IkSdKYdV+DN6CqOO+889h6662ftv7HP/4xz3rWs5a5vapixowZfP3rXx/y+Wc84xlAZ3KXpUuX9lzn2muvzbvf/W4+/vGPj7ivwb9PtxNOOIG9996b888/nzvuuIO99tprxH3PnDmT97///fz2t7/l2muvZZ999uHhhx/mOc95zjL3NRYGPEmSVlMrejKFftHLpBCS2rX//vtz6qmncuqpp5KE66+/np133vmP2s2YMYPTTjuNf/u3fwPg/vvv5yUveQlHHXUUCxcu5AUveAEPP/wwd911Fy984QuH3d+GG27IAw88MGJdRxxxBJ/4xCd48MEHAYbd19Zbb81tt93GHXfcweTJk582OcvixYvZbLPNgM41hd01DGx3sA022IAXv/jFvOMd7+DAAw9kwoQJPPvZz2bKlCl84xvf4OCDD6aquOGGG9hpp51G/D2WxWvwJEmSJK1QJ5xwAkuWLGHHHXdku+2244QTThiy3fHHH8/999/P9ttvz0477cQll1zCxIkTOeuss5g1axY77rjjk0Mml+VVr3oV559//rCTrAxYd911OeaYY7j77rsBht3X+uuvz2c/+9knJ0DZcMMN2WijjQB473vfy3HHHcfOO+/8tB7EvffemwULFjw5ycpghx56KP/5n//5tOvzvvrVr/LFL36RnXbaie222+7JyWiWR1a3285Nnz695s2bt7LLkCRppbMHb2j24GlNcvPNN/OiF71oZZfRlx566CE22GADqoqjjjqKqVOncuyxx457HUP9jZNcW1XTh2pvD54kSZIkDfL5z3+eadOmsd1227F48WLe/OY3r+ySeuI1eJIkSZI0yLHHHrtSeuyWlz14kiRJktQnDHiSJEnSamx1m1NDvRvL39aAJ0mSJK2m1ltvPe677z5DXh+qKu677z7WW2+9Ub3Oa/AkSZKk1dSkSZNYtGgR99xzz8ouRS1Yb731mDRpdDMmG/AkSZKk1dQ666zDlClTVnYZWoU4RFOSJEmS+oQBT5IkSZL6hAFPkiRJkvqEAU+SJEmS+oQBT5IkSZL6hAFPkiRJkvqEAU+SJEmS+oQBT5IkSZL6hAFPkiRJkvqEAU+SJEmS+oQBT5IkSZL6hAFPkiRJkvqEAU+SJEmS+oQBT5IkSZL6hAFPkiRJkvqEAU+SJEmS+oQBT5IkSZL6xNptbjzJAcCngQnAF6rqY4Oe/xSwd7P4TOB5VfWcNmtakTJj0souYZVUFy9a2SVIkiRJa6TWAl6SCcBpwAxgEXBNkjlVtWCgTVUd29X+7cDObdUjSZIkSf2uzSGauwELq+q2qnoMmA0ctIz2s4Cvt1iPJEmSJPW1NgPeZsCdXcuLmnV/JMmWwBTgBy3WI0mSJEl9bVWZZOUw4NyqenyoJ5McmWReknn33HPPOJcmSZIkSauHNgPeXcDmXcuTmnVDOYxlDM+sqjOranpVTZ84ceIKLFGSJEmS+kebAe8aYGqSKUnWpRPi5gxulGQb4LnAj1qsRZIkSZL6XmsBr6qWAkcDFwI3A+dU1U1JTkoys6vpYcDsqqq2apEkSZKkNUGr98GrqrnA3EHrThy0/KE2a5AkSZL37x2O9+9Vv1lVJlmRJEmSJC0nA54kSZIk9QkDniRJkiT1CQOeJEmSJPUJA54kSZIk9QkDniRJkiT1CQOeJEmSJPUJA54kSZIk9QkDniRJkiT1CQOeJEmSJPUJA54kSZIk9QkDniRJkiT1CQOeJEmSJPUJA54kSZIk9QkDniRJkiT1CQOeJEmSJPUJA54kSZIk9QkDniRJkiT1CQOeJEmSJPUJA54kSZIk9QkDniRJkiT1CQOeJEmSJPUJA54kSZIk9QkDniRJkiT1CQOeJEmSJPUJA54kSZIk9QkDniRJkiT1CQOeJEmSJPUJA54kSZIk9QkDniRJkiT1CQOeJEmSJPWJVgNekgOS3JpkYZL3DdPmkCQLktyU5Gtt1iNJkiRJ/WzttjacZAJwGjADWARck2ROVS3oajMVOA54aVXdn+R5bdUjSZIkSf2uzR683YCFVXVbVT0GzAYOGtTmH4DTqup+gKq6u8V6JEmSJKmvtRnwNgPu7Fpe1Kzr9kLghUn+J8lVSQ5osR5JkiRJ6mutDdEcxf6nAnsBk4AfJtmhqn7X3SjJkcCRAFtsscV41yhJkiRJq4U2e/DuAjbvWp7UrOu2CJhTVUuq6nbgZ3QC39NU1ZlVNb2qpk+cOLG1giVJkiRpdTZiwEtycJINm8fHJ/lmkl162PY1wNQkU5KsCxwGzBnU5r/o9N6RZFM6QzZvG0X9kiRJkqRGLz14J1TVg0n+AtgP+CLwuZFeVFVLgaOBC4GbgXOq6qYkJyWZ2TS7ELgvyQLgEuA9VXXfWH4RSZIkSVrT9XIN3uPNv68Ezqyqbyf5SC8br6q5wNxB607selzAu5ofSZIkSdJy6KUH764kZwCHAnOTPKPH10mSJEmSxlEvQe0QOkMp929mt9wYeE+rVUmSJEmSRq2XgHdGVX2zqn4OUFW/Af6m3bIkSZIkSaPVS8DbrnshyQRg13bKkSRJkiSN1bABL8lxSR4EdkzyQJIHm+W7gW+NW4WSJEmSpJ4MG/Cq6p+rakPgX6rq2VW1YfOzSVUdN441SpIkSZJ60MsQzQ8keX2SEwCSbJ5kt5brkiRJkiSNUi8B7zRgd+DwZvmhZp0kSZIkaRXSy43O/7yqdklyPUBV3Z9k3ZbrkiRJkiSNUi89eEuamTMLIMlE4IlWq5IkSZIkjVovAe8zwPnAnyQ5GbgC+GirVUmSJEmSRm3EIZpV9dUk1wL7AgFeXVU3t16ZJEmSJGlUeunBA9gU+H1V/Ttwb5IpLdYkSZIkSRqDEQNekg8C/wcYuPfdOsB/tlmUJEmSJGn0eunB+ytgJvAwQFX9GtiwzaIkSZIkSaPXS8B7rKqKp2bRfFa7JUmSJEmSxqKXgHdOkjOA5yT5B+B7wOfbLUuSJEmSNFq9zKJ5SpIZwAPA1sCJVXVx65VJkiRJkkZlxICX5E3AD6vqPeNQjyRJkiRpjEYMeMAWwBlJJgPXAj8ELq+q+S3WJUmSJEkapRGvwauqD1bVPsB2wOXAe+gEPUmSJEnSKqSXIZrHAy8FNgCuB/6RTtCTJEmSJK1Cehmi+RpgKfBt4DLgR1X1aKtVSZIkSZJGrZchmrsA+wFXAzOAG5Nc0XZhkiRJkqTR6WWI5vbAnsBfAtOBO3GIpiRJkiStcnoZovkxOjNnfga4pqqWtFuSJEmSJGksRhyiCXyvqj5RVVcOhLsk72i5LkmSJEnSKPUS8P52iHVHrOA6JEmSJEnLadghmklmAYcDU5LM6XpqQ+C3bRcmSZIkSRqdZV2DdyXwG2BT4F+71j8I3NBmUZIkSZKk0Rs24FXVL4FfAruPXzmSJEmSpLHq5Rq8MUtyQJJbkyxM8r4hnj8iyT1J5jc/f99mPZIkSZLUz3q5TcKYJJkAnEbn5uiLgGuSzKmqBYOanl1VR7dVhyRJkiStKXrqwUuyfpKtR7nt3YCFVXVbVT0GzAYOGm2BkiRJkqTejBjwkrwKmA98t1meNmhWzeFsBtzZtbyoWTfYXye5Icm5STbvYbuSJEmSpCH00oP3ITq9cb8DqKr5wJQVtP//BiZX1Y7AxcCXh2qU5Mgk85LMu+eee1bQriVJkiSpv/QS8JZU1eJB66qH190FdPfITWrWPbWRqvuq6tFm8QvArkNtqKrOrKrpVTV94sSJPexakiRJktY8vQS8m5IcDkxIMjXJqXTukTeSa4CpSaYkWRc4DHja0M4kf9q1OBO4uce6JUmSJEmD9BLw3g5sBzwKfA1YDLxzpBdV1VLgaOBCOsHtnKq6KclJSWY2zY5JclOSnwDHAEeM/leQJEmSJEFvt0nYpqo+AHxgtBuvqrnA3EHrTux6fBxw3Gi3K0n9LDMmrewSVkl18aKVXYIkSau8Xnrw/jXJzUk+nGT71iuSJEmSJI3JiAGvqvYG9gbuAc5IcmOS41uvTJIkSZI0Kj3d6Lyq/r+q+gzwFjr3xDtxhJdIkiRJksZZLzc6f1GSDyW5ERiYQdMLRCRJkiRpFdPLJCtfAs4G9q+qX7dcjyRJkiRpjEYMeFW1+3gUIkmSJElaPsMGvCTnVNUhzdDM6n4KqKrasfXqJEmSJEk9W1YP3juafw8cj0IkSZIkSctn2ElWquo3zcO3VdUvu3+At41PeZIkSZKkXvVym4QZQ6x7+YouRJIkSZK0fJZ1Dd5b6fTUbZXkhq6nNgT+p+3CJEmSJEmjs6xr8L4GfAf4Z+B9XesfrKrftlqVJEmSJGnUhg14VbUYWAzMAkjyPGA9YIMkG1TVr8anREmSJElSL0a8Bi/Jq5L8HLgduAy4g07PniRJkiRpFdLLJCsfAV4C/KyqpgD7Ale1WpUkSZIkadR6CXhLquo+YK0ka1XVJcD0luuSJEmSJI3SsiZZGfC7JBsAPwS+muRu4OF2y5IkSZIkjVYvPXgHAX8AjgW+C/wCeFWbRUmSJEmSRm/EHryq6u6t+3KLtUiSJEmSlsOIAS/Jg0ANWr0YmAe8u6pua6MwSZIkSdLo9HIN3r8Bi+jc+DzAYcDzgeuALwF7tVWcJEmSJKl3vVyDN7OqzqiqB6vqgao6E9i/qs4GnttyfZIkSZKkHvUS8H6f5JAkazU/hwCPNM8NHropSZIkSVpJehmi+Trg08Bn6QS6q4DXJ1kfOLrF2qS+kRmTVnYJq6S6eNHKLkGSJKmv9DKL5m0Mf1uEK1ZsOZIkSZKksRpxiGaSFyb5fpKfNss7Jjm+/dIkSZIkSaPRyzV4nweOA5YAVNUNdGbSlCRJkiStQnoJeM+sqqsHrVvaRjGSJEmSpLHrJeDdm+T5NDNmJnkt8JtWq5IkSZIkjVovs2geBZwJbJPkLuB24PWtViVJkiRJGrVeZ9HcL8mzgLWq6sH2y5IkSZIkjdaIAS/JM4C/BiYDaycBoKpO6uG1B9C5h94E4AtV9bFh2v01cC7w4qqa12vxkiRJkqSn9DJE81vAYuBa4NFeN5xkAnAaMANYBFyTZE5VLRjUbkPgHcCPe922JEmSJOmP9RLwJlXVAWPY9m7AwmaIJ0lmAwcBCwa1+zDwceA9Y9iHJEmSJKnRyyyaVybZYQzb3gy4s2t5UbPuSUl2ATavqm+PYfuSJEmSpC699OD9BXBEktvpDNEMUFW14/LsOMlawCeBI3poeyRwJMAWW2yxPLuVJEmSpL7VS8B7+Ri3fRewedfypGbdgA2B7YFLm4lb/h9gTpKZgydaqaoz6dyqgenTp9cY65EkSZKkvtbLbRJ+OcZtXwNMTTKFTrA7DDi8a7uLgU0HlpNcCvyjs2hKkiRJ0tj0cg3emFTVUuBo4ELgZuCcqropyUlJZra1X0mSJElaUw3bg5fkGVXV820RhlJVc4G5g9adOEzbvZZnX5IkSZK0pltWD96PAJJ8ZZxqkSRJkiQth2Vdg7duksOBPZK8ZvCTVfXN9sqSJEmSJI3WsgLeW4DXAc8BXjXouQIMeJIkSZK0Chk24FXVFcAVSeZV1RfHsSZJkiRJ0hj0ch+8ryQ5BnhZs3wZcHpVLWmvLEmSJEnSaPUS8D4LrNP8C/A3wOeAv2+rKEmSJEnS6PUS8F5cVTt1Lf8gyU/aKkiSJEmSNDa93Oj88STPH1hIshXweHslSZIkSZLGopcevPcAlyS5DQiwJfB3rVYlSZIkSRq1EQNeVX0/yVRg62bVrVX1aLtlSZIkSZJGq5cePJpAd0PLtUiSJEmSlkNPAU+SJEnSmiEzJq3sElZJdfGilV1CT3qZZEWSJEmStBoYMeCl4/VJTmyWt0iyW/ulSZIkSZJGo5cevM8CuwOzmuUHgdNaq0iSJEmSNCa9XIP351W1S5LrAarq/iTrtlyXJEmSJGmUeunBW5JkAlAASSYCT7RalSRJkiRp1HoJeJ8Bzgeel+Rk4Argo61WJUmSJEkatV5udP7VJNcC+wIBXl1VN7demSRJkiRpVEYMeEk2Bu4Gvt61bp2qWtJmYZIkSZKk0elliOZ1wD3Az4CfN4/vSHJdkl3bLE6SJEmS1LteAt7FwCuqatOq2gR4OXAB8DY6t1CQJEmSJK0Cegl4L6mqCwcWquoiYPequgp4RmuVSZIkSZJGpZf74P0myf8BZjfLhwL/29w6wdslSJIkSdIqopcevMOBScB/NT9bNOsmAIe0V5okSZIkaTR6uU3CvcDbh3l64YotR5IkSZI0Vr3cJmEi8F5gO2C9gfVVtU+LdUmSJEmSRqmXIZpfBW4BpgD/BNwBXNNiTZIkSZKkMegl4G1SVV8EllTVZVX1RsDeO0mSJElaxfQyi+aS5t/fJHkl8Gtg4/ZKkiRJkiSNRS8B7yNJNgLeDZwKPBt4Z6tVSZIkSZJGrZchmvdX1eKq+mlV7V1VuwK/7WXjSQ5IcmuShUneN8Tzb0lyY5L5Sa5Isu1ofwFJkiRJUkcvAe/UHtc9TXMj9NOAlwPbArOGCHBfq6odqmoa8Angkz3UI0mSJEkawrBDNJPsDuwBTEzyrq6nnk3nJucj2Q1YWFW3NdubDRwELBhoUFUPdLV/FlC9ly5JkiRJ6rasa/DWBTZo2mzYtf4B4LU9bHsz4M6u5UXAnw9ulOQo4F3N/pydU5IkSZLGaNiAV1WXAZclOauqftlWAVV1GnBaksOB44E3DG6T5EjgSIAtttiirVIkSZIkabXWyyyaz0hyJjC5u31VjdTbdhewedfypGbdcGYDnxvqiao6EzgTYPr06Q7jlCRJkqQh9BLwvgGcDnwBeHwU274GmJpkCp1gdxhweHeDJFOr6ufN4iuBnyNJkiRJGpNeAt7SqhqyZ21ZqmppkqOBC+lMyvKlqropyUnAvKqaAxydZD86N1O/nyGGZ0qSJEmSetNLwPvvJG8DzgceHVhZVSPeC6+q5gJzB607sevxO3ovVZIkSZK0LL0EvIFetfd0rStgqxVfjiRJkiRprEYMeFU1ZTwKkSRJkiQtn7VGapDkmUmOb2bSJMnUJAe2X5okSZIkaTRGDHjAfwCPAXs0y3cBH2mtIkmSJEnSmPQS8J5fVZ+gM9MlVfV7IK1WJUmSJEkatV4C3mNJ1qczsQpJnk/XbJqSJEmSpFVDL7NofhD4LrB5kq8CLwWOaLMoSZIkSdLo9TKL5sVJrgNeQmdo5juq6t7WK5MkSZIkjUovs2j+FbC0qr5dVRcAS5O8uv3SJEmSJEmj0cs1eB+sqsUDC1X1OzrDNiVJkiRJq5BeAt5QbXq5dk+SJEmSNI56CXjzknwyyfObn08C17ZdmCRJkiRpdHoJeG+nc6Pzs4HZwCPAUW0WJUmSJEkavWUOtUwyAbigqvYep3okSZIkSWO0zB68qnoceCLJRuNUjyRJkiRpjHqZLOUh4MYkFwMPD6ysqmNaq0qSJEmSNGq9BLxvNj+SJEmSpFXYiAGvqr6cZH1gi6q6dRxqkiRJkiSNwYizaCZ5FTAf+G6zPC3JnLYLkyRJkiSNTi+3SfgQsBvwO4Cqmg9s1WJNkiRJkqQx6CXgLamqxYPWPdFGMZIkSZKksetlkpWbkhwOTEgyFTgGuLLdsiRJkiRJo9VLD97bge2AR4GvAYuBd7ZZlCRJkiRp9IbtwUuyHvAW4AXAjcDuVbV0vAqTJEmSJI3OsnrwvgxMpxPuXg6cMi4VSZIkSZLGZFnX4G1bVTsAJPkicPX4lCRJkiRJGotl9eAtGXjg0ExJkiRJWvUtqwdvpyQPNI8DrN8sB6iqenbr1UmSJEmSejZswKuqCeNZiCRJkiRp+fRymwRJkiRJ0mrAgCdJkiRJfaLVgJfkgCS3JlmY5H1DPP+uJAuS3JDk+0m2bLMeSZIkSepnrQW8JBOA0+jcQ29bYFaSbQc1ux6YXlU7AucCn2irHkmSJEnqd2324O0GLKyq26rqMWA2cFB3g6q6pKp+3yxeBUxqsR5JkiRJ6mttBrzNgDu7lhc164bzJuA7LdYjSZIkSX1tWffBGzdJXg9MB/5ymOePBI4E2GKLLcaxMkmSJElafbTZg3cXsHnX8qRm3dMk2Q/4ADCzqh4dakNVdWZVTa+q6RMnTmylWEmSJEla3bUZ8K4BpiaZkmRd4DBgTneDJDsDZ9AJd3e3WIskSZIk9b3WAl5VLQWOBi4EbgbOqaqbkpyUZGbT7F+ADYBvJJmfZM4wm5MkSZIkjaDVa/Cqai4wd9C6E7se79fm/iVJkiRpTdLqjc4lSZIkSePHgCdJkiRJfcKAJ0mSJEl9woAnSZIkSX3CgCdJkiRJfcKAJ0mSJEl9woAnSZIkSX3CgCdJkiRJfcKAJ0mSJEl9woAnSZIkSX3CgCdJkiRJfcKAJ0mSJEl9woAnSZIkSX3CgCdJkiRJfcKAJ0mSJEl9woAnSZIkSX3CgCdJkiRJfcKAJ0mSJEl9woAnSZIkSX3CgCdJkiRJfcKAJ0mSJEl9woAnSZIkSX3CgCdJkiRJfcKAJ0mSJEl9woAnSZIkSX3CgCdJkiRJfcKAJ0mSJEl9woAnSZIkSX3CgCdJkiRJfcKAJ0mSJEl9woAnSZIkSX2i1YCX5IAktyZZmOR9Qzz/siTXJVma5LVt1iJJkiRJ/a61gJdkAnAa8HJgW2BWkm0HNfsVcATwtbbqkCRJkqQ1xdotbns3YGFV3QaQZDZwELBgoEFV3dE890SLdUiSJEnSGqHNIZqbAXd2LS9q1kmSJEmSWrBaTLKS5Mgk85LMu+eee1Z2OZIkSZK0Smoz4N0FbN61PKlZN2pVdWZVTa+q6RMnTlwhxUmSJODjbncAAA7aSURBVElSv2kz4F0DTE0yJcm6wGHAnBb3J0mSJElrtNYCXlUtBY4GLgRuBs6pqpuSnJRkJkCSFydZBBwMnJHkprbqkSRJkqR+1+YsmlTVXGDuoHUndj2+hs7QTUmSJEnSclotJlmRJEmSJI3MgCdJkiRJfcKAJ0mSJEl9woAnSZIkSX3CgCdJkiRJfcKAJ0mSJEl9woAnSZIkSX3CgCdJkiRJfcKAJ0mSJEl9woAnSZIkSX3CgCdJkiRJfcKAJ0mSJEl9woAnSZIkSX3CgCdJkiRJfcKAJ0mSJEl9woAnSZIkSX3CgCdJkiRJfcKAJ0mSJEl9woAnSZIkSX3CgCdJkiRJfcKAJ0mSJEl9woAnSZIkSX3CgCdJkiRJfcKAJ0mSJEl9woAnSZIkSX3CgCdJkiRJfcKAJ0mSJEl9woAnSZIkSX3CgCdJkiRJfcKAJ0mSJEl9woAnSZIkSX2i1YCX5IAktyZZmOR9Qzz/jCRnN8//OMnkNuuRJEmSpH7WWsBLMgE4DXg5sC0wK8m2g5q9Cbi/ql4AfAr4eFv1SJIkSVK/a7MHbzdgYVXdVlWPAbOBgwa1OQj4cvP4XGDfJGmxJkmSJEnqW20GvM2AO7uWFzXrhmxTVUuBxcAmLdYkSZIkSX1r7ZVdQC+SHAkc2Sw+lOTWlVnPKmpT4N6VXQSAnbCrPI8VjYbHi3rlsaLR8HhRrzxWhrblcE+0GfDuAjbvWp7UrBuqzaIkawMbAfcN3lBVnQmc2VKdfSHJvKqavrLr0KrPY0Wj4fGiXnmsaDQ8XtQrj5XRa3OI5jXA1CRTkqwLHAbMGdRmDvCG5vFrgR9UVbVYkyRJkiT1rdZ68KpqaZKjgQuBCcCXquqmJCcB86pqDvBF4CtJFgK/pRMCJUmSJElj0Oo1eFU1F5g7aN2JXY8fAQ5us4Y1iENY1SuPFY2Gx4t65bGi0fB4Ua88VkYpjoiUJEmSpP7Q5jV4kiRJkqRxZMAbZ0lenaSSbNPS9qcn+Uwb29aqKcnjSeYnuSnJT5K8O8ky/99OMjnJT5vH05K8Ynyq1YqU5APN3/2G5hj48zFsY68ke3Qtn5XktSu20iH3e0SSP2t7P2uy7v/Pu9Z9KMk/No9fkuTHzbFzc5IPLWNb/5bkru73liQzk7yvtV9Aq7SRjq9hXvPkOcrg955R7PeOJJuOvmKtbEkuSbL/oHXvTHL7aN9LkvxZknNXbIX9Y7W4D16fmQVc0fz7wRW54SRrV9U8YN6K3K5WeX+oqmkASZ4HfA14Nr0fX9OA6Qy6XlartiS7AwcCu1TVo80Jz7pj2NRewEPAlSuwvF4cAfwU+PU471dP+TJwSFX9JMkEYOuhGjWh7q+AO4G/BC4BaCZLGzw79sBn0dLWqtZqa9A5yl6snPcerTxfpzOh4oVd6w4D3lBVPxzceFnvJVX1azoz8GsI9uCNoyQbAH8BvIlmxtDmG6zLknwryW1JPpbkdUmuTnJjkuc37SYmOS/JNc3PS5v1H0rylST/Q2dG0r2SXDCwvyT/0WznhiR/3az/XJJ5zTf//9RV3x1J/inJdc1rWullVHuq6m7gSODodExI8i/NMXNDkjd3t29uYXIScGjzLf6hSXZL8qMk1ye5MsmQJ31a6f4UuLeqHgWoqnur6tdJ9m3+djcm+VKSZ8DTv/VuvkW/NMlk4C3Asc3ff89m2y9r/va3DfTmJTktyczm8flJvtQ8fmOSk5vHr2/eu+YnOaM5/iY0vYI/bWo6ttnmdOCrTdv1x+s/mp7mecBvAKrq8apaMEy7vYCbgM/R+XISeLIX9t+bx2clOT3Jj4FPNH/r5zTvQ/cl+dum3f9NMqPp/bm8+by5bqAnp3n+1V37+GqSg5Js13Vs3ZBkagv/PbSCNO8vH2/+Zj8beG8ZOEcZ6r1nGec5myS5qDln+QKwSt1pWqNyLvDK5tyD5jj4M+D5y3gveX6Sq5r3lI8keWjgtXlqJNIRSb6Z5LtJfp7kEyvjl1uVGPDG10HAd6vqZ8B9SXZt1u9E543uRcDfAC+sqt2ALwBvb9p8GvhUVb0Y+OvmuQHbAvtV1Sye7gRgcVXtUFU7Aj9o1n+guWHkjsBfJtmx6zX3VtUudD7Ihx1moVVXVd1G59Ykz6PzZcLi5rh5MfAPSaZ0tX0MOBE4u6qmVdXZwC3AnlW1c/PcR8f7d1BPLgI2b06ePpvkL5OsB5wFHFpVO9AZpfHW4TZQVXcAp9N5b5lWVZc3T/0pnS+jDgQ+1qy7HBgIgJvRed+hWffDJC8CDgVe2vQoPw68jk4P8WZVtX1T039U1bl0vsV/XbPfPyzvfwyNyaeAW5vA/ubm+BnKLDrfvJ9P5+RsnWHaTQL2qKp3Af8DvBTYDriNp46d3en02NwNzGg+bw4FBi4t+CKd3l2SbATsAXybzmfkp5tjazqwaEy/scbT2s25zDsZNKJkmPee4c5zPghcUVXb0TkGtxin+rWCVdVvgauBlzerDgPOAQbP+Nj9XvJpOv/v78Cy/7+fRue9ZAc6X1pvviJrX90Y8MbXLGB283g2T30Tek1V/ab5Jv4XdE7cAG4EJjeP9wP+Pcl8OkNinp1OjyDAnGFOkPYDThtYqKr7m4eHJLkOuJ7Oh++2Xa/5ZvPvtV371urr/wX+tjlufgxsAoz0zfdGwDeab8Y+RecY0Sqmqh4CdqXTY3sPcDbwZuD25ksk6AzBe9kYNv9fVfVE06PzJ826y4E9k2wLLAD+N8mf8tQJ+75NPdc0x9u+wFZ0Tu63SnJqkgOAB8ZQj8ZmuGmyC6CqTqITli4CDge+O7hh8037K+gcEw/QeR/Zf3C7xjeq6vHm8eV0jr2X0fnCcIckmwH3V9XDwDrA55PcCHyD5nOoqi4DpiaZSOcz8rxmiNaPgPcn+T/Aln4psEpY5vHF6M8nhjvPeRnwnwBV9W3g/uE3odXAwDBNmn+/PkSb7veS3em8R0DnEpThfL+qFje3YFsAbLkiil1deQ3eOEmyMbAPnQ+5otPDUnS+mXy0q+kTXctP8NTfaC3gJc2B271dgIdHUccUOj1zL66q+5OcBXR/azuw78fx+FgtJdmKzt/vbjpDWd5eVRcOajN5GZv4MHBJVf1V0+7SNurU8ms+AC8FLm1OlI9aRvOlPPWl3nA9NQO635PS7OuuJM8BDgB+CGwMHAI8VFUPpvNm9OWqOm7wxpLsRCcUvKV5zRtH2L9WjPuA5w5atzFw+8BCVf0C+FySzwP3JNmkqu7rar8/8Bzgxubz5pnAH4ALhthf92fRD+kcj1sAH6BzDd9r6QQ/gGOB/6UzgmUtoPuz7f8Cr6dz8vd3TZ1fa4ZsvRKYm+TNVfUDtDKNdHyN9nxiWec56h/fAj6VZBfgmVV1bZIdBrXp+by2S/fn1hp/DmsP3vh5LfCVqtqyqiZX1eZ03gT3HOF1Ay7iqeGaJJnWw2supuuEL8lz6Uy+8TCwOMmf8FQ3ufpA86336cC/V+cmlxcCbx0YUpXkhUmeNehlDwIbdi1vBNzVPD6i3Yo1Vkm2HnQd0jQ6IwAmJ3lBs+5vgMuax3fQ6WGDzvCnAYP//styFZ3hVj+kc6L+jzx1wv594LXpTPRDko2TbJnOdX9rVdV5wPHALmPYr8ag6eX9TZJ94MkvGg+gM9EXSV6Zp86ep9I5KfrdoM3MAv6++dyaDEwBZiR55gj7vhPYFJjaDBu/gs7xMjCRwkbAb6rqCTrH6YSul59F5zhj4LrA5our26rqM3ROELsvLdBKMNLx1YPB7wHDnef8kE4PM0lezh+HSq1GmuPmEuBLDN17N9hVPPWZddiyGuopBrzxM4vO2PFu59F1wfoIjgGmNxeXL6DzTfhIPgI8N53JDX4C7F1VP6EzNPMWOl3d/9Pj/rXqWr+5SP0m4Ht0PiQHJs/5Ap2hCtc1Qy7P4I+/1boE2LbZxqHAJ4B/TnL9EG216tgA+HKSBUluoDPE7X10ejy+0fToPUEn8EPnmPh0knl0TuQH/DfwV3n6JCvDuZzOdTULgevofFt/OTx5In48cFFTz8V0ruXbjE4P43w6w6wGevjOAk6Pk6y07W+BE5r//j8A/qnptYNOsLq1ee4rdK6JfPLYaELcAXRGmgDQDK+8AnhVD/v+MTAwXPhyOsfCwMn/Z4E3NJ9N29D1jX1V/S9wM/AfXds6BPhpU+v2dHr5tPIt6/gayeD3nuHOc/6JzsRPNwGvAX61Yn8FrQRfp9N730vAeyfwruZz5QXA4jYL6xfpfMkvSZK08jXB8kY6twDxZE5agzXvB3+oqkpyGDCrqg5a2XWt6vx2XpIkrRKS7EdnJs1PGe4k0bm04N+b4eS/w2u4e2IPniRJkiT1Ca/BkyRJkqQ+YcCTJEmSpD5hwJMkSZKkPmHAkyStUZK8Okkl2aZZ/rMk5w7TdnJzixGSTE/ymfGsVZKk0XKSFUnSGiXJ2cCfAT+oqg8uo93awCTggqrafrzqkyRpediDJ0laYyTZAPgL4E3AYc267l66I5LMSfID4PuDXrtXkguaxx9K8qUklya5LckxXe1en+Tq5gbOZySZ0PycleSnSW5Mcux4/c6SpDWL98GTJK1JDgK+W1U/S3Jfkl2B+wa12QXYsap+m2TyMra1DbA3sCFwa5LPAS8ADgVeWlVLknwWeB1wE7DZQE9gkuesyF9KkqQB9uBJktYks4DZzePZzfJgF1fVb3vY1rer6tGquhe4G/gTYF86N+a9Jsn8Znkr4DZgqySnJjkAeGA5fw9JkoZkD54kaY2QZGNgH2CHJAVMAAo4bVDTh3vc5KNdjx+n85ka4MtVddwQ+98J2B94C3AI8MZR/QKSJPXAHjxJ0pritcBXqmrLqppcVZsDtwObr8B9fB94bZLnQSdUJtkyyabAWlV1HnA8nWGgkiStcPbgSZLWFLOAjw9adx7wR71tY1VVC5IcD1yUZC1gCXAU8AfgP5p1rMh9SpLUzdskSJIkSVKfcIimJEmSJPUJA54kSZIk9QkDniRJkiT1CQOeJEmSJPUJA54kSZIk9QkDniRJkiT1CQOeJEmSJPUJA54kSZIk9Yn/H3u6fQ25xOFQAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 1080x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KDmaIkLoEvM9"
      },
      "source": [
        "# Data Preprocessing \n",
        "\n",
        "def remove_stopwords(input_text):\n",
        "    stopwords_list = stopwords.words('english')\n",
        "    wl = [\"not\", \"no\"]\n",
        "    words = input_text.split() \n",
        "    clean_words = [word for word in words if (word not in stopwords_list or word in wl) and len(word) > 1] \n",
        "    return \" \".join(clean_words)\n",
        "\n",
        "def remove_mentions(input_text):\n",
        "    for i in range(len(input_text)):\n",
        "        input_text[i] = re.sub(r'@\\w+', '', input_text[i])\n",
        "    return input_text\n",
        "\n",
        "def lower_case(input_text):\n",
        "    for i in range(len(input_text)):\n",
        "        input_text[i] = input_text[i].lower()\n",
        "    return input_text\n",
        "\n",
        "def remove_http(input_text):\n",
        "    for i in range(len(input_text)):\n",
        "        input_text[i] = re.sub(r'http\\S+', '',input_text[i])\n",
        "    return input_text\n",
        "\n",
        "def remove_punctuation(input_text):\n",
        "    for i in range(len(input_text)):\n",
        "        input_text[i] = re.sub(r'[^\\w\\s]','',input_text[i])\n",
        "    return input_text\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wIbp0PtFHWGH",
        "outputId": "48c25206-8804-4f4a-bef3-31d19ab1d2a1"
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "\n",
        "data_2 = data_df[['text', 'airline_sentiment']]\n",
        "preprocessed_data = data_2.apply(remove_mentions).apply(remove_http).apply(remove_punctuation).apply(lower_case)\n",
        "clean_text = []\n",
        "for tweet in preprocessed_data.text:\n",
        "    clean = remove_stopwords(tweet)\n",
        "    clean_text.append(clean)\n",
        "\n",
        "X = clean_text\n",
        "Y = preprocessed_data['airline_sentiment']\n",
        "from sklearn.model_selection import train_test_split\n",
        "Y = Y.map({'negative':0, 'positive':1, 'neutral':2}).astype(int)\n",
        "X_train,X_test,y_train,y_test = train_test_split(X, Y, test_size=0.1, random_state=42)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z7LchRDTIjkc"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "vectorizer = TfidfVectorizer()\n",
        "text_features_train = vectorizer.fit_transform(X_train)\n",
        "text_features_test = vectorizer.transform(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bJuD_cRGLmaE"
      },
      "source": [
        "from gensim.models import Word2Vec\n",
        "sentences = [line.split() for line in clean_text]\n",
        "w2v = Word2Vec(sentences, size=50, min_count = 0, window = 5,workers=4,iter=500)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ndz6coNXLJkR",
        "outputId": "911047eb-d758-4cc6-8526-8eaeb3461d27"
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "t = Tokenizer()\n",
        "t.fit_on_texts(clean_text)\n",
        "vocab_size = len(t.word_index) + 1\n",
        "encoded_docs = t.texts_to_sequences(clean_text)\n",
        "padded_docs = pad_sequences(encoded_docs, maxlen=20, padding='post')\n",
        "embedding_dict = dict()\n",
        "for i in w2v.wv.vocab:\n",
        "    embedding_dict[i] = w2v[i]\n",
        "\n",
        "embedding_matrix = np.zeros((vocab_size, 50))\n",
        "for word, i in t.word_index.items():\n",
        "    embedding_vector = embedding_dict.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        embedding_matrix[i] = embedding_vector"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  # This is added back by InteractiveShellApp.init_path()\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WSLUlKrNMhuu"
      },
      "source": [
        "def results(labels, pred):\n",
        "    print(confusion_matrix(labels,pred))  \n",
        "    print(classification_report(labels,pred))  \n",
        "    print(accuracy_score(labels, pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lshO7d2SLgKb",
        "outputId": "9f359506-8947-41d3-a7a6-6d2dd6754f90"
      },
      "source": [
        "# SVM \n",
        "\n",
        "def svm(training_features, labels_train, test_features, labels_test):\n",
        "    for c in [1, 5, 10, 50]:\n",
        "    #changing the parameter C to get the optimal classification\n",
        "        model = LinearSVC(C=c)\n",
        "        model.fit(training_features, labels_train)\n",
        "        print (\"Accuracy of svm for C=%s: %s\" \n",
        "           % (c, accuracy_score(labels_train, model.predict(training_features))))\n",
        "        results(labels_test, model.predict(test_features))\n",
        "\n",
        "\n",
        "svm(text_features_train,y_train, text_features_test,y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of svm for C=1: 0.9564359441408622\n",
            "[[847  24  53]\n",
            " [ 44 161  33]\n",
            " [115  38 149]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.92      0.88       924\n",
            "           1       0.72      0.68      0.70       238\n",
            "           2       0.63      0.49      0.55       302\n",
            "\n",
            "    accuracy                           0.79      1464\n",
            "   macro avg       0.73      0.70      0.71      1464\n",
            "weighted avg       0.78      0.79      0.78      1464\n",
            "\n",
            "0.7903005464480874\n",
            "Accuracy of svm for C=5: 0.9780661809350334\n",
            "[[826  28  70]\n",
            " [ 45 156  37]\n",
            " [115  37 150]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.89      0.86       924\n",
            "           1       0.71      0.66      0.68       238\n",
            "           2       0.58      0.50      0.54       302\n",
            "\n",
            "    accuracy                           0.77      1464\n",
            "   macro avg       0.71      0.68      0.69      1464\n",
            "weighted avg       0.76      0.77      0.77      1464\n",
            "\n",
            "0.773224043715847\n",
            "Accuracy of svm for C=10: 0.98224043715847\n",
            "[[804  34  86]\n",
            " [ 46 153  39]\n",
            " [109  41 152]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.87      0.85       924\n",
            "           1       0.67      0.64      0.66       238\n",
            "           2       0.55      0.50      0.53       302\n",
            "\n",
            "    accuracy                           0.76      1464\n",
            "   macro avg       0.69      0.67      0.68      1464\n",
            "weighted avg       0.75      0.76      0.75      1464\n",
            "\n",
            "0.7575136612021858\n",
            "Accuracy of svm for C=50: 0.9885397692774742\n",
            "[[773  45 106]\n",
            " [ 46 149  43]\n",
            " [108  43 151]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.84      0.84       924\n",
            "           1       0.63      0.63      0.63       238\n",
            "           2       0.50      0.50      0.50       302\n",
            "\n",
            "    accuracy                           0.73      1464\n",
            "   macro avg       0.66      0.65      0.65      1464\n",
            "weighted avg       0.73      0.73      0.73      1464\n",
            "\n",
            "0.7329234972677595\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CRFDXwHhMdkW",
        "outputId": "908a00c8-fa74-4ed6-e9b3-44df1fe82e5c"
      },
      "source": [
        "# Naive Bayes\n",
        "\n",
        "def naiive_bayes(training_features, labels_train, test_features, labels_test):\n",
        "    clf = MultinomialNB()\n",
        "    clf.fit(training_features, labels_train)\n",
        "    print (\"Accuracy of Naiive Bayes: %s\" \n",
        "         % ( accuracy_score(labels_test, clf.predict(test_features))))\n",
        "    results(labels_test, clf.predict(test_features))\n",
        "\n",
        "naiive_bayes(text_features_train,y_train, text_features_test,y_test)    "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of Naiive Bayes: 0.6967213114754098\n",
            "[[920   0   4]\n",
            " [178  55   5]\n",
            " [253   4  45]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.68      1.00      0.81       924\n",
            "           1       0.93      0.23      0.37       238\n",
            "           2       0.83      0.15      0.25       302\n",
            "\n",
            "    accuracy                           0.70      1464\n",
            "   macro avg       0.82      0.46      0.48      1464\n",
            "weighted avg       0.75      0.70      0.62      1464\n",
            "\n",
            "0.6967213114754098\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kHpWqmz2MpGY"
      },
      "source": [
        "import tensorflow as tf\n",
        "y_one_hot = tf.keras.utils.to_categorical(\n",
        "    Y,\n",
        "    num_classes=3,\n",
        "    dtype='int32'\n",
        ")\n",
        "\n",
        "x_train_DL, x_test_DL,y_train_DL,y_test_DL = train_test_split(padded_docs,y_one_hot,test_size=0.1,random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qveJxsGlNXXv",
        "outputId": "49f41eb3-785d-4a0f-91b1-89e78f0d5f7b"
      },
      "source": [
        "# Feed forward network\n",
        "\n",
        "model = Sequential()\n",
        "embedding_layer = Embedding(vocab_size,50,embeddings_initializer = Constant(embedding_matrix),input_length=20, trainable=False)\n",
        "model.add(embedding_layer)\n",
        "model.add(Dense(128,activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(128,activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(3,activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "print(model.summary())\n",
        "model.fit(x_train_DL,y_train_DL,epochs = 50, batch_size=128)\n",
        "ans = model.predict(x_test_DL)\n",
        "labels = [np.where(r==1)[0][0] for r in y_test_DL]\n",
        "ans = np.argmax(ans,axis=1)\n",
        "accuracy_score(ans,labels)\n",
        "results(ans,labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 20, 50)            726400    \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 20, 128)           6528      \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 20, 128)           0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 20, 128)           16512     \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 20, 128)           0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 2560)              0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 3)                 7683      \n",
            "=================================================================\n",
            "Total params: 757,123\n",
            "Trainable params: 30,723\n",
            "Non-trainable params: 726,400\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/50\n",
            "103/103 [==============================] - 3s 20ms/step - loss: 0.9033 - accuracy: 0.6217\n",
            "Epoch 2/50\n",
            "103/103 [==============================] - 2s 20ms/step - loss: 0.5994 - accuracy: 0.7595\n",
            "Epoch 3/50\n",
            "103/103 [==============================] - 2s 20ms/step - loss: 0.5557 - accuracy: 0.7821\n",
            "Epoch 4/50\n",
            "103/103 [==============================] - 2s 19ms/step - loss: 0.5155 - accuracy: 0.7978\n",
            "Epoch 5/50\n",
            "103/103 [==============================] - 2s 20ms/step - loss: 0.5097 - accuracy: 0.7928\n",
            "Epoch 6/50\n",
            "103/103 [==============================] - 2s 19ms/step - loss: 0.4726 - accuracy: 0.8107\n",
            "Epoch 7/50\n",
            "103/103 [==============================] - 2s 20ms/step - loss: 0.4676 - accuracy: 0.8190\n",
            "Epoch 8/50\n",
            "103/103 [==============================] - 2s 20ms/step - loss: 0.4473 - accuracy: 0.8210\n",
            "Epoch 9/50\n",
            "103/103 [==============================] - 2s 20ms/step - loss: 0.4363 - accuracy: 0.8293\n",
            "Epoch 10/50\n",
            "103/103 [==============================] - 2s 20ms/step - loss: 0.4395 - accuracy: 0.8241\n",
            "Epoch 11/50\n",
            "103/103 [==============================] - 2s 20ms/step - loss: 0.4174 - accuracy: 0.8379\n",
            "Epoch 12/50\n",
            "103/103 [==============================] - 2s 20ms/step - loss: 0.4192 - accuracy: 0.8335\n",
            "Epoch 13/50\n",
            "103/103 [==============================] - 2s 20ms/step - loss: 0.3899 - accuracy: 0.8443\n",
            "Epoch 14/50\n",
            "103/103 [==============================] - 2s 19ms/step - loss: 0.3988 - accuracy: 0.8410\n",
            "Epoch 15/50\n",
            "103/103 [==============================] - 2s 20ms/step - loss: 0.3803 - accuracy: 0.8444\n",
            "Epoch 16/50\n",
            "103/103 [==============================] - 2s 20ms/step - loss: 0.3741 - accuracy: 0.8509\n",
            "Epoch 17/50\n",
            "103/103 [==============================] - 2s 20ms/step - loss: 0.3677 - accuracy: 0.8563\n",
            "Epoch 18/50\n",
            "103/103 [==============================] - 2s 20ms/step - loss: 0.3627 - accuracy: 0.8581\n",
            "Epoch 19/50\n",
            "103/103 [==============================] - 2s 20ms/step - loss: 0.3462 - accuracy: 0.8636\n",
            "Epoch 20/50\n",
            "103/103 [==============================] - 2s 20ms/step - loss: 0.3464 - accuracy: 0.8669\n",
            "Epoch 21/50\n",
            "103/103 [==============================] - 2s 19ms/step - loss: 0.3423 - accuracy: 0.8652\n",
            "Epoch 22/50\n",
            "103/103 [==============================] - 2s 19ms/step - loss: 0.3315 - accuracy: 0.8696\n",
            "Epoch 23/50\n",
            "103/103 [==============================] - 2s 19ms/step - loss: 0.3365 - accuracy: 0.8680\n",
            "Epoch 24/50\n",
            "103/103 [==============================] - 2s 19ms/step - loss: 0.3275 - accuracy: 0.8674\n",
            "Epoch 25/50\n",
            "103/103 [==============================] - 2s 19ms/step - loss: 0.3242 - accuracy: 0.8728\n",
            "Epoch 26/50\n",
            "103/103 [==============================] - 2s 19ms/step - loss: 0.3142 - accuracy: 0.8767\n",
            "Epoch 27/50\n",
            "103/103 [==============================] - 2s 20ms/step - loss: 0.3182 - accuracy: 0.8703\n",
            "Epoch 28/50\n",
            "103/103 [==============================] - 2s 20ms/step - loss: 0.3181 - accuracy: 0.8752\n",
            "Epoch 29/50\n",
            "103/103 [==============================] - 2s 20ms/step - loss: 0.3155 - accuracy: 0.8769\n",
            "Epoch 30/50\n",
            "103/103 [==============================] - 2s 20ms/step - loss: 0.3125 - accuracy: 0.8763\n",
            "Epoch 31/50\n",
            "103/103 [==============================] - 2s 20ms/step - loss: 0.3163 - accuracy: 0.8755\n",
            "Epoch 32/50\n",
            "103/103 [==============================] - 2s 20ms/step - loss: 0.2977 - accuracy: 0.8818\n",
            "Epoch 33/50\n",
            "103/103 [==============================] - 2s 20ms/step - loss: 0.3019 - accuracy: 0.8807\n",
            "Epoch 34/50\n",
            "103/103 [==============================] - 2s 20ms/step - loss: 0.2927 - accuracy: 0.8825\n",
            "Epoch 35/50\n",
            "103/103 [==============================] - 2s 20ms/step - loss: 0.2910 - accuracy: 0.8859\n",
            "Epoch 36/50\n",
            "103/103 [==============================] - 2s 20ms/step - loss: 0.2838 - accuracy: 0.8890\n",
            "Epoch 37/50\n",
            "103/103 [==============================] - 2s 20ms/step - loss: 0.2860 - accuracy: 0.8840\n",
            "Epoch 38/50\n",
            "103/103 [==============================] - 2s 20ms/step - loss: 0.2907 - accuracy: 0.8852\n",
            "Epoch 39/50\n",
            "103/103 [==============================] - 2s 20ms/step - loss: 0.2951 - accuracy: 0.8792\n",
            "Epoch 40/50\n",
            "103/103 [==============================] - 2s 20ms/step - loss: 0.2743 - accuracy: 0.8898\n",
            "Epoch 41/50\n",
            "103/103 [==============================] - 2s 20ms/step - loss: 0.2842 - accuracy: 0.8908\n",
            "Epoch 42/50\n",
            "103/103 [==============================] - 2s 20ms/step - loss: 0.2696 - accuracy: 0.8960\n",
            "Epoch 43/50\n",
            "103/103 [==============================] - 2s 20ms/step - loss: 0.2666 - accuracy: 0.8936\n",
            "Epoch 44/50\n",
            "103/103 [==============================] - 2s 20ms/step - loss: 0.2689 - accuracy: 0.8910\n",
            "Epoch 45/50\n",
            "103/103 [==============================] - 2s 20ms/step - loss: 0.2695 - accuracy: 0.8953\n",
            "Epoch 46/50\n",
            "103/103 [==============================] - 2s 20ms/step - loss: 0.2598 - accuracy: 0.8997\n",
            "Epoch 47/50\n",
            "103/103 [==============================] - 2s 20ms/step - loss: 0.2634 - accuracy: 0.8938\n",
            "Epoch 48/50\n",
            "103/103 [==============================] - 2s 20ms/step - loss: 0.2708 - accuracy: 0.8918\n",
            "Epoch 49/50\n",
            "103/103 [==============================] - 2s 20ms/step - loss: 0.2575 - accuracy: 0.8992\n",
            "Epoch 50/50\n",
            "103/103 [==============================] - 2s 20ms/step - loss: 0.2607 - accuracy: 0.8935\n",
            "[[787  28  87]\n",
            " [ 39 171  40]\n",
            " [ 98  39 175]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.87      0.86       902\n",
            "           1       0.72      0.68      0.70       250\n",
            "           2       0.58      0.56      0.57       312\n",
            "\n",
            "    accuracy                           0.77      1464\n",
            "   macro avg       0.72      0.71      0.71      1464\n",
            "weighted avg       0.77      0.77      0.77      1464\n",
            "\n",
            "0.7739071038251366\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5nU2WLRCNdnE",
        "outputId": "8327410a-4428-4136-c324-b62f2c78530d"
      },
      "source": [
        "# LSTM\n",
        "\n",
        "embedding_layer = Embedding(vocab_size,50,embeddings_initializer = Constant(embedding_matrix),input_length=20, trainable=True)\n",
        "model.add(embedding_layer)\n",
        "model.add(LSTM(32, activation = 'relu',return_sequences=True))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(LSTM(32, activation = 'relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(3,activation = 'softmax'))\n",
        "print(model.summary())\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "model.fit(x_train_DL,y_train_DL,epochs = 20,batch_size=256)\n",
        "ans = model.predict(x_test_DL)\n",
        "labels = [np.where(r==1)[0][0] for r in y_test_DL]\n",
        "ans = np.argmax(ans,axis=1)\n",
        "accuracy_score(ans,labels)\n",
        "results(ans,labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 20, 50)            726400    \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 20, 128)           6528      \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 20, 128)           0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 20, 128)           16512     \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 20, 128)           0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 2560)              0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 3)                 7683      \n",
            "_________________________________________________________________\n",
            "embedding_1 (Embedding)      (None, 3, 50)             726400    \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 3, 32)             10624     \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 3, 32)             0         \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 32)                8320      \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 3)                 99        \n",
            "=================================================================\n",
            "Total params: 1,502,566\n",
            "Trainable params: 776,166\n",
            "Non-trainable params: 726,400\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/20\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense/kernel:0', 'dense/bias:0', 'dense_1/kernel:0', 'dense_1/bias:0', 'dense_2/kernel:0', 'dense_2/bias:0'] when minimizing the loss.\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense/kernel:0', 'dense/bias:0', 'dense_1/kernel:0', 'dense_1/bias:0', 'dense_2/kernel:0', 'dense_2/bias:0'] when minimizing the loss.\n",
            "52/52 [==============================] - 4s 35ms/step - loss: 1.0664 - accuracy: 0.6256\n",
            "Epoch 2/20\n",
            "52/52 [==============================] - 2s 34ms/step - loss: 0.9276 - accuracy: 0.6222\n",
            "Epoch 3/20\n",
            "52/52 [==============================] - 2s 34ms/step - loss: 0.9159 - accuracy: 0.6256\n",
            "Epoch 4/20\n",
            "52/52 [==============================] - 2s 34ms/step - loss: 0.9106 - accuracy: 0.6289\n",
            "Epoch 5/20\n",
            "52/52 [==============================] - 2s 34ms/step - loss: 0.9176 - accuracy: 0.6247\n",
            "Epoch 6/20\n",
            "52/52 [==============================] - 2s 34ms/step - loss: 0.9171 - accuracy: 0.6252\n",
            "Epoch 7/20\n",
            "52/52 [==============================] - 2s 35ms/step - loss: 0.9125 - accuracy: 0.6257\n",
            "Epoch 8/20\n",
            "52/52 [==============================] - 2s 35ms/step - loss: 0.9161 - accuracy: 0.6242\n",
            "Epoch 9/20\n",
            "52/52 [==============================] - 2s 34ms/step - loss: 0.9135 - accuracy: 0.6264\n",
            "Epoch 10/20\n",
            "52/52 [==============================] - 2s 35ms/step - loss: 0.9117 - accuracy: 0.6266\n",
            "Epoch 11/20\n",
            "52/52 [==============================] - 2s 35ms/step - loss: 0.9140 - accuracy: 0.6244\n",
            "Epoch 12/20\n",
            "52/52 [==============================] - 2s 35ms/step - loss: 0.9194 - accuracy: 0.6190\n",
            "Epoch 13/20\n",
            "52/52 [==============================] - 2s 35ms/step - loss: 0.9085 - accuracy: 0.6294\n",
            "Epoch 14/20\n",
            "52/52 [==============================] - 2s 35ms/step - loss: 0.9202 - accuracy: 0.6210\n",
            "Epoch 15/20\n",
            "52/52 [==============================] - 2s 35ms/step - loss: 0.9188 - accuracy: 0.6220\n",
            "Epoch 16/20\n",
            "52/52 [==============================] - 2s 35ms/step - loss: 0.9163 - accuracy: 0.6254\n",
            "Epoch 17/20\n",
            "52/52 [==============================] - 2s 35ms/step - loss: 0.9079 - accuracy: 0.6308\n",
            "Epoch 18/20\n",
            "52/52 [==============================] - 2s 35ms/step - loss: 0.9136 - accuracy: 0.6250\n",
            "Epoch 19/20\n",
            "52/52 [==============================] - 2s 35ms/step - loss: 0.9133 - accuracy: 0.6256\n",
            "Epoch 20/20\n",
            "52/52 [==============================] - 2s 34ms/step - loss: 0.9108 - accuracy: 0.6275\n",
            "[[924 238 302]\n",
            " [  0   0   0]\n",
            " [  0   0   0]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.63      0.77      1464\n",
            "           1       0.00      0.00      0.00         0\n",
            "           2       0.00      0.00      0.00         0\n",
            "\n",
            "    accuracy                           0.63      1464\n",
            "   macro avg       0.33      0.21      0.26      1464\n",
            "weighted avg       1.00      0.63      0.77      1464\n",
            "\n",
            "0.6311475409836066\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2OaDnLTvNjLs",
        "outputId": "d3c101b5-5955-4b5c-bb44-b6865160d3ef"
      },
      "source": [
        "# CNN\n",
        "\n",
        "model = Sequential()\n",
        "embedding_layer = Embedding(vocab_size,50,embeddings_initializer = Constant(embedding_matrix),input_length=20, trainable=False)\n",
        "model.add(embedding_layer)\n",
        "model.add(Convolution1D(filters=100,\n",
        "                        kernel_size=5,\n",
        "                        activation='relu'))\n",
        "model.add(GlobalMaxPooling1D())\n",
        "model.add(Dense(128,activation = 'relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(3,activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "model.fit(x_train_DL,y_train_DL,epochs=20)\n",
        "ans = model.predict(x_test_DL)\n",
        "labels = [np.where(r==1)[0][0] for r in y_test_DL]\n",
        "ans = np.argmax(ans,axis=1)\n",
        "accuracy_score(ans,labels)\n",
        "results(ans,labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "412/412 [==============================] - 2s 4ms/step - loss: 0.8218 - accuracy: 0.6780\n",
            "Epoch 2/20\n",
            "412/412 [==============================] - 2s 4ms/step - loss: 0.5290 - accuracy: 0.7933\n",
            "Epoch 3/20\n",
            "412/412 [==============================] - 2s 4ms/step - loss: 0.4624 - accuracy: 0.8136\n",
            "Epoch 4/20\n",
            "412/412 [==============================] - 2s 4ms/step - loss: 0.3929 - accuracy: 0.8434\n",
            "Epoch 5/20\n",
            "412/412 [==============================] - 2s 4ms/step - loss: 0.3373 - accuracy: 0.8733\n",
            "Epoch 6/20\n",
            "412/412 [==============================] - 2s 4ms/step - loss: 0.2601 - accuracy: 0.9012\n",
            "Epoch 7/20\n",
            "412/412 [==============================] - 2s 4ms/step - loss: 0.2286 - accuracy: 0.9109\n",
            "Epoch 8/20\n",
            "412/412 [==============================] - 2s 4ms/step - loss: 0.1755 - accuracy: 0.9367\n",
            "Epoch 9/20\n",
            "412/412 [==============================] - 2s 4ms/step - loss: 0.1527 - accuracy: 0.9428\n",
            "Epoch 10/20\n",
            "412/412 [==============================] - 2s 4ms/step - loss: 0.1525 - accuracy: 0.9427\n",
            "Epoch 11/20\n",
            "412/412 [==============================] - 2s 4ms/step - loss: 0.1225 - accuracy: 0.9573\n",
            "Epoch 12/20\n",
            "412/412 [==============================] - 2s 4ms/step - loss: 0.1134 - accuracy: 0.9570\n",
            "Epoch 13/20\n",
            "412/412 [==============================] - 2s 4ms/step - loss: 0.0986 - accuracy: 0.9652\n",
            "Epoch 14/20\n",
            "412/412 [==============================] - 2s 4ms/step - loss: 0.0921 - accuracy: 0.9707\n",
            "Epoch 15/20\n",
            "412/412 [==============================] - 2s 4ms/step - loss: 0.0883 - accuracy: 0.9699\n",
            "Epoch 16/20\n",
            "412/412 [==============================] - 2s 4ms/step - loss: 0.0839 - accuracy: 0.9718\n",
            "Epoch 17/20\n",
            "412/412 [==============================] - 2s 4ms/step - loss: 0.0842 - accuracy: 0.9700\n",
            "Epoch 18/20\n",
            "412/412 [==============================] - 2s 4ms/step - loss: 0.0743 - accuracy: 0.9762\n",
            "Epoch 19/20\n",
            "412/412 [==============================] - 2s 4ms/step - loss: 0.0683 - accuracy: 0.9777\n",
            "Epoch 20/20\n",
            "412/412 [==============================] - 2s 4ms/step - loss: 0.0725 - accuracy: 0.9751\n",
            "[[725  30  81]\n",
            " [ 72 154  51]\n",
            " [127  54 170]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.78      0.87      0.82       836\n",
            "           1       0.65      0.56      0.60       277\n",
            "           2       0.56      0.48      0.52       351\n",
            "\n",
            "    accuracy                           0.72      1464\n",
            "   macro avg       0.66      0.64      0.65      1464\n",
            "weighted avg       0.71      0.72      0.71      1464\n",
            "\n",
            "0.7165300546448088\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oR2jU74EOrHp"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}